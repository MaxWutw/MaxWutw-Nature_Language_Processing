{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8b8cae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !python3 -m spacy download en_core_web_sm\n",
    "# !python3 -m spacy download de_core_news_sm\n",
    "!python3 -m spacy download zh_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e879f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from typing import Iterable, List\n",
    "from torch.nn import Transformer\n",
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm as tqdm\n",
    "from torchtext.data.metrics import bleu_score\n",
    "import sys\n",
    "import spacy \n",
    "from torchtext.legacy.datasets import Multi30k\n",
    "from torchtext.legacy.data import Field, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adca8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_ger = spacy.load('zh_core_web_sm')\n",
    "spacy_eng = spacy.load('en_core_web_sm')\n",
    "\n",
    "def tokenize_ger(text):\n",
    "    return [token.text for token in spacy_ger.tokenizer(text)]\n",
    "            \n",
    "def tokenize_eng(text):\n",
    "    return [token.text for token in spacy_eng.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f876ad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(model, sentence, german, english, device, max_length=50):\n",
    "    # Load german tokenizer\n",
    "    spacy_ger = spacy.load(\"zh_core_web_sm\")\n",
    "\n",
    "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
    "    if type(sentence) == str:\n",
    "        tokens = [token.text.lower() for token in spacy_ger(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    # Add <SOS> and <EOS> in beginning and end respectively\n",
    "    tokens.insert(0, german.init_token)\n",
    "    tokens.append(german.eos_token)\n",
    "\n",
    "    # Go through each german token and convert to an index\n",
    "    text_to_indices = [german.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    # Convert to Tensor\n",
    "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
    "\n",
    "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
    "    for i in range(max_length):\n",
    "        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(sentence_tensor, trg_tensor)\n",
    "\n",
    "        best_guess = output.argmax(2)[-1, :].item()\n",
    "        outputs.append(best_guess)\n",
    "\n",
    "        if best_guess == english.vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    translated_sentence = [english.vocab.itos[idx] for idx in outputs]\n",
    "    # remove start token\n",
    "    return translated_sentence[1:]\n",
    "\n",
    "\n",
    "def bleu(data, model, german, english, device):\n",
    "    targets = []\n",
    "    outputs = []\n",
    "\n",
    "    for example in data:\n",
    "        src = vars(example)[\"src\"]\n",
    "        trg = vars(example)[\"trg\"]\n",
    "\n",
    "        prediction = translate_sentence(model, src, german, english, device)\n",
    "        prediction = prediction[:-1]  # remove <eos> token\n",
    "\n",
    "        targets.append([trg])\n",
    "        outputs.append(prediction)\n",
    "\n",
    "    return bleu_score(outputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6391ce96",
   "metadata": {},
   "outputs": [],
   "source": [
    "german = Field(tokenize=tokenize_ger, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\")\n",
    "\n",
    "english = Field(\n",
    "    tokenize=tokenize_eng, lower=True, init_token=\"<sos>\", eos_token=\"<eos>\"\n",
    ")\n",
    "\n",
    "train_data, valid_data, test_data = Multi30k.splits(\n",
    "    exts=(\".ch\", \".en\"), fields=(german, english)\n",
    ")\n",
    "\n",
    "german.build_vocab(train_data, max_size=10000, min_freq=2)\n",
    "english.build_vocab(train_data, max_size=10000, min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c253a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_size,\n",
    "        src_vocab_size,\n",
    "        trg_vocab_size,\n",
    "        src_pad_idx,\n",
    "        num_heads,\n",
    "        num_encoder_layers,\n",
    "        num_decoder_layers,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        max_len,\n",
    "        device,\n",
    "    ):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
    "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n",
    "        self.trg_position_embedding = nn.Embedding(max_len, embedding_size)\n",
    "\n",
    "        self.device = device\n",
    "        self.transformer = nn.Transformer(\n",
    "            embedding_size,\n",
    "            num_heads,\n",
    "            num_encoder_layers,\n",
    "            num_decoder_layers,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "        )\n",
    "        self.fc_out = nn.Linear(embedding_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
    "\n",
    "        # (N, src_len)\n",
    "        return src_mask.to(self.device)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_seq_length, N = src.shape\n",
    "        trg_seq_length, N = trg.shape\n",
    "\n",
    "        src_positions = (\n",
    "            torch.arange(0, src_seq_length)\n",
    "            .unsqueeze(1)\n",
    "            .expand(src_seq_length, N)\n",
    "            .to(self.device)\n",
    "        )\n",
    "\n",
    "        trg_positions = (\n",
    "            torch.arange(0, trg_seq_length)\n",
    "            .unsqueeze(1)\n",
    "            .expand(trg_seq_length, N)\n",
    "            .to(self.device)\n",
    "        )\n",
    "\n",
    "        embed_src = self.dropout(\n",
    "            (self.src_word_embedding(src) + self.src_position_embedding(src_positions))\n",
    "        )\n",
    "        embed_trg = self.dropout(\n",
    "            (self.trg_word_embedding(trg) + self.trg_position_embedding(trg_positions))\n",
    "        )\n",
    "\n",
    "        src_padding_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length).to(\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        out = self.transformer(\n",
    "            embed_src,\n",
    "            embed_trg,\n",
    "            src_key_padding_mask=src_padding_mask,\n",
    "            tgt_mask=trg_mask,\n",
    "        )\n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9ed42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.')\n",
    "else:\n",
    "    print('CUDA is available!')\n",
    "device = \"cuda\" if train_on_gpu else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac24749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "num_epochs = 5\n",
    "learning_rate = 3e-4\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958d2ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = len(german.vocab)\n",
    "trg_vocab_size = len(english.vocab)\n",
    "embedding_size = 512\n",
    "num_heads = 8\n",
    "num_encoder_layers = 3\n",
    "num_decoder_layers = 3\n",
    "dropout = 0.1\n",
    "max_len = 100\n",
    "forward_expansion = 4\n",
    "src_pad_idx = english.vocab.stoi[\"<pad>\"]\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c059b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_iter, valid_iter, test_iter = BucketIterator.splits(\n",
    "#     (train_data, valid_data, test_data),\n",
    "#     batch_size = batch_size,\n",
    "#     sort_within_batch = True,\n",
    "#     sort_key = lambda x : len(x.src),\n",
    "#     device=device\n",
    "# )\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=batch_size,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.src),\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = iter(train_iterator)\n",
    "print(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ec8532",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(\n",
    "    embedding_size,\n",
    "    src_vocab_size,\n",
    "    trg_vocab_size,\n",
    "    src_pad_idx,\n",
    "    num_heads,\n",
    "    num_encoder_layers,\n",
    "    num_decoder_layers,\n",
    "    forward_expansion,\n",
    "    dropout,\n",
    "    max_len,\n",
    "    device,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95f7e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "sentence = \"Ich bin Gymnasiast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefb7fbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.eval()\n",
    "    translated = translate_sentence(\n",
    "        model, sentence, german, english, device, max_length=100\n",
    "    )\n",
    "    print(f\"Translated sentence: {translated}\")\n",
    "    \n",
    "    model.train()\n",
    "    for idx, x in enumerate(tqdm(train_iterator)):\n",
    "        data, target = x.src.to(device), x.trg.to(device)\n",
    "        \n",
    "        output = model(data, target[:-1, :])\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        target = target[1:].reshape(-1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "        step += 1\n",
    "    print(f\"epoch: {epoch+1}, loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e3905",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu_score = bleu(test_data, model, german, english, device)\n",
    "print(f\"Bleu score: {bleu_score * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5271fc70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3292e52e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bb27a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
